{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cc6e73-ccac-4665-bb51-1af86b180ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EasyEnsembleClassifier | Threshold objective: F1 ===\n",
      "Chosen threshold (val): 0.4413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.04      0.07     17762\n",
      "           1       0.10      0.95      0.18      1976\n",
      "\n",
      "    accuracy                           0.13     19738\n",
      "   macro avg       0.49      0.50      0.13     19738\n",
      "weighted avg       0.80      0.13      0.08     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  682 17080]\n",
      " [   94  1882]]\n",
      "\n",
      "=== EasyEnsembleClassifier | Threshold objective: BalancedAcc ===\n",
      "Chosen threshold (val): 0.5129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.62      0.74     17762\n",
      "           1       0.10      0.38      0.16      1976\n",
      "\n",
      "    accuracy                           0.60     19738\n",
      "   macro avg       0.50      0.50      0.45     19738\n",
      "weighted avg       0.82      0.60      0.68     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11093  6669]\n",
      " [ 1217   759]]\n",
      "\n",
      "=== EasyEnsembleClassifier | Threshold objective: FixedRecall ===\n",
      "Chosen threshold (val): 0.4563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.08      0.15     17762\n",
      "           1       0.10      0.92      0.18      1976\n",
      "\n",
      "    accuracy                           0.16     19738\n",
      "   macro avg       0.50      0.50      0.16     19738\n",
      "weighted avg       0.82      0.16      0.15     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1419 16343]\n",
      " [  166  1810]]\n",
      "\n",
      "=== BalancedRandomForest | Threshold objective: F1 ===\n",
      "Chosen threshold (val): 0.2400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.55      0.50      0.09     19738\n",
      "weighted avg       0.91      0.10      0.02     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    1 17761]\n",
      " [    0  1976]]\n",
      "\n",
      "=== BalancedRandomForest | Threshold objective: BalancedAcc ===\n",
      "Chosen threshold (val): 0.4033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.51      0.65     17762\n",
      "           1       0.10      0.49      0.17      1976\n",
      "\n",
      "    accuracy                           0.51     19738\n",
      "   macro avg       0.50      0.50      0.41     19738\n",
      "weighted avg       0.82      0.51      0.60     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9041 8721]\n",
      " [1003  973]]\n",
      "\n",
      "=== BalancedRandomForest | Threshold objective: FixedRecall ===\n",
      "Chosen threshold (val): 0.3467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.09      0.17     17762\n",
      "           1       0.10      0.91      0.18      1976\n",
      "\n",
      "    accuracy                           0.17     19738\n",
      "   macro avg       0.50      0.50      0.17     19738\n",
      "weighted avg       0.82      0.17      0.17     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1622 16140]\n",
      " [  184  1792]]\n",
      "\n",
      "=== Extra Models (EEC & BRF) — Summary (sorted by PR_AUC) ===\n",
      "                    Model    Objective  Accuracy  Balanced_Acc  Precision  \\\n",
      "3    BalancedRandomForest           F1  0.100162      0.500028   0.100117   \n",
      "4    BalancedRandomForest  BalancedAcc  0.507346      0.500708   0.100371   \n",
      "5    BalancedRandomForest  FixedRecall  0.172966      0.499101   0.099933   \n",
      "0  EasyEnsembleClassifier           F1  0.129902      0.495413   0.099251   \n",
      "1  EasyEnsembleClassifier  BalancedAcc  0.600466      0.504322   0.102181   \n",
      "2  EasyEnsembleClassifier  FixedRecall  0.163593      0.497941   0.099708   \n",
      "\n",
      "     Recall        F1   ROC_AUC    PR_AUC  Threshold  \n",
      "3  1.000000  0.182011  0.505068  0.103938   0.240000  \n",
      "4  0.492409  0.166752  0.505068  0.103938   0.403333  \n",
      "5  0.906883  0.180028  0.505068  0.103938   0.346667  \n",
      "0  0.952429  0.179769  0.502919  0.101595   0.441306  \n",
      "1  0.384109  0.161421  0.502919  0.101595   0.512926  \n",
      "2  0.915992  0.179840  0.502919  0.101595   0.456344  \n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# EXTRA MODELS FOR IMBALANCED DATA (EEC & BRF)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, balanced_accuracy_score,\n",
    "    classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Imbalanced-learn ensembles\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# --------- Load artifacts & preprocess (same as your baseline) ----------\n",
    "preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "X_train, X_test, y_train, y_test = joblib.load(\"splits.pkl\")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "# Validation split from TRAIN (stratified)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_proc, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train\n",
    ")\n",
    "\n",
    "# --------- Models to try ----------\n",
    "models = {\n",
    "    \"EasyEnsembleClassifier\": EasyEnsembleClassifier(\n",
    "        n_estimators=10,            # number of balanced AdaBoost sub-ensembles\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"BalancedRandomForest\": BalancedRandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "def evaluate_with_threshold(model, name, objective=\"F1\", fixed_recall=0.80):\n",
    "    # Fit on the ORIGINAL (imbalanced) train fold — these models internally rebalance\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # --- choose threshold on validation ---\n",
    "    # NOTE: Some classifiers (like BRF/EEC) expose predict_proba; if not, use decision_function fallback.\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    else:\n",
    "        # fall back to decision_function (rare for these two, but safe)\n",
    "        val_scores = model.decision_function(X_val)\n",
    "        # map scores to pseudo-proba via min-max for thresholding (won't affect AUCs)\n",
    "        smin, smax = val_scores.min(), val_scores.max()\n",
    "        val_proba = (val_scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, val_proba)\n",
    "\n",
    "    if objective == \"F1\":\n",
    "        f1s = (2 * precisions * recalls) / (precisions + recalls + 1e-9)\n",
    "        best_idx = int(np.argmax(f1s[:-1]))  # last PR point has no threshold\n",
    "    elif objective == \"BalancedAcc\":\n",
    "        bal_scores = []\n",
    "        for thr in thresholds:\n",
    "            y_val_pred = (val_proba >= thr).astype(int)\n",
    "            bal_scores.append(balanced_accuracy_score(y_val, y_val_pred))\n",
    "        best_idx = int(np.argmax(bal_scores))\n",
    "    elif objective == \"FixedRecall\":\n",
    "        cand = np.where(recalls[:-1] >= fixed_recall)[0]\n",
    "        best_idx = cand[np.argmax(precisions[cand])] if len(cand) else int(np.argmax(recalls[:-1]))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown objective\")\n",
    "\n",
    "    best_thr = float(thresholds[best_idx])\n",
    "\n",
    "    # --- evaluate on test ---\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        test_proba = model.predict_proba(X_test_proc)[:, 1]\n",
    "    else:\n",
    "        test_scores = model.decision_function(X_test_proc)\n",
    "        smin, smax = test_scores.min(), test_scores.max()\n",
    "        test_proba = (test_scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "    y_pred = (test_proba >= best_thr).astype(int)\n",
    "\n",
    "    print(f\"\\n=== {name} | Threshold objective: {objective} ===\")\n",
    "    print(f\"Chosen threshold (val): {best_thr:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Objective\": objective,\n",
    "        \"Threshold\": best_thr,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Balanced_Acc\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC_AUC\": roc_auc_score(y_test, test_proba),\n",
    "        \"PR_AUC\": average_precision_score(y_test, test_proba),\n",
    "    }\n",
    "\n",
    "# Run both models under three thresholding rules (so you can show you tried)\n",
    "rows = []\n",
    "for mname, model in models.items():\n",
    "    rows.append(evaluate_with_threshold(model, mname, objective=\"F1\"))\n",
    "    rows.append(evaluate_with_threshold(model, mname, objective=\"BalancedAcc\"))\n",
    "    rows.append(evaluate_with_threshold(model, mname, objective=\"FixedRecall\", fixed_recall=0.80))\n",
    "\n",
    "df_extra = pd.DataFrame(rows)\n",
    "print(\"\\n=== Extra Models (EEC & BRF) — Summary (sorted by PR_AUC) ===\")\n",
    "print(df_extra.sort_values([\"PR_AUC\",\"ROC_AUC\"], ascending=False)[\n",
    "    [\"Model\",\"Objective\",\"Accuracy\",\"Balanced_Acc\",\"Precision\",\"Recall\",\"F1\",\"ROC_AUC\",\"PR_AUC\",\"Threshold\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9b36c-a3ee-4c62-a448-9ca93af0db1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
