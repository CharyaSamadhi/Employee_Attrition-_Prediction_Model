{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "853ee045-5771-4741-af3b-590abd33d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression + RandomOverSampler ===\n",
      "Chosen threshold (val F1-max): 0.4730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.03      0.06     17762\n",
      "           1       0.10      0.97      0.18      1976\n",
      "\n",
      "    accuracy                           0.12     19738\n",
      "   macro avg       0.50      0.50      0.12     19738\n",
      "weighted avg       0.82      0.12      0.07     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  530 17232]\n",
      " [   60  1916]]\n",
      "\n",
      "=== Random Forest + RandomOverSampler ===\n",
      "Chosen threshold (val F1-max): 0.0733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.00      0.01     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.52      0.50      0.09     19738\n",
      "weighted avg       0.85      0.10      0.02     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   67 17695]\n",
      " [    5  1971]]\n",
      "\n",
      "=== Gradient Boosting + RandomOverSampler ===\n",
      "Chosen threshold (val F1-max): 0.3419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.00      0.01     17762\n",
      "           1       0.10      0.99      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.49      0.50      0.10     19738\n",
      "weighted avg       0.81      0.10      0.03     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   85 17677]\n",
      " [   11  1965]]\n",
      "\n",
      "=== XGBoost + RandomOverSampler ===\n",
      "Chosen threshold (val F1-max): 0.1975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.01      0.01     17762\n",
      "           1       0.10      0.99      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.47      0.50      0.10     19738\n",
      "weighted avg       0.76      0.10      0.03     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  108 17654]\n",
      " [   21  1955]]\n",
      "\n",
      "=== Logistic Regression + RandomUnderSampler ===\n",
      "Chosen threshold (val F1-max): 0.4623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.02      0.04     17762\n",
      "           1       0.10      0.98      0.18      1976\n",
      "\n",
      "    accuracy                           0.12     19738\n",
      "   macro avg       0.50      0.50      0.11     19738\n",
      "weighted avg       0.83      0.12      0.05     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  342 17420]\n",
      " [   34  1942]]\n",
      "\n",
      "=== Random Forest + RandomUnderSampler ===\n",
      "Chosen threshold (val F1-max): 0.3367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.00      0.00     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.52      0.50      0.09     19738\n",
      "weighted avg       0.86      0.10      0.02     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   17 17745]\n",
      " [    1  1975]]\n",
      "\n",
      "=== Gradient Boosting + RandomUnderSampler ===\n",
      "Chosen threshold (val F1-max): 0.4141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.04      0.08     17762\n",
      "           1       0.10      0.95      0.18      1976\n",
      "\n",
      "    accuracy                           0.13     19738\n",
      "   macro avg       0.49      0.50      0.13     19738\n",
      "weighted avg       0.80      0.13      0.09     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  752 17010]\n",
      " [  101  1875]]\n",
      "\n",
      "=== XGBoost + RandomUnderSampler ===\n",
      "Chosen threshold (val F1-max): 0.2231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.01      0.01     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.51      0.50      0.10     19738\n",
      "weighted avg       0.85      0.10      0.03     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  103 17659]\n",
      " [    8  1968]]\n",
      "\n",
      "=== Logistic Regression + SMOTE-Tomek ===\n",
      "Chosen threshold (val F1-max): 0.4560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.08      0.15     17762\n",
      "           1       0.10      0.92      0.18      1976\n",
      "\n",
      "    accuracy                           0.17     19738\n",
      "   macro avg       0.50      0.50      0.17     19738\n",
      "weighted avg       0.82      0.17      0.15     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1464 16298]\n",
      " [  163  1813]]\n",
      "\n",
      "=== Random Forest + SMOTE-Tomek ===\n",
      "Chosen threshold (val F1-max): 0.0533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.01      0.02     17762\n",
      "           1       0.10      0.99      0.18      1976\n",
      "\n",
      "    accuracy                           0.11     19738\n",
      "   macro avg       0.50      0.50      0.10     19738\n",
      "weighted avg       0.82      0.11      0.04     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  192 17570]\n",
      " [   22  1954]]\n",
      "\n",
      "=== Gradient Boosting + SMOTE-Tomek ===\n",
      "Chosen threshold (val F1-max): 0.1036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.00      0.00     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.52      0.50      0.09     19738\n",
      "weighted avg       0.86      0.10      0.02     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   33 17729]\n",
      " [    2  1974]]\n",
      "\n",
      "=== XGBoost + SMOTE-Tomek ===\n",
      "Chosen threshold (val F1-max): 0.0638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.03      0.06     17762\n",
      "           1       0.10      0.97      0.18      1976\n",
      "\n",
      "    accuracy                           0.13     19738\n",
      "   macro avg       0.50      0.50      0.12     19738\n",
      "weighted avg       0.82      0.13      0.07     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  558 17204]\n",
      " [   59  1917]]\n",
      "\n",
      "=== Logistic Regression + SMOTEENN ===\n",
      "Chosen threshold (val F1-max): 0.6473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.04      0.08     17762\n",
      "           1       0.10      0.96      0.18      1976\n",
      "\n",
      "    accuracy                           0.13     19738\n",
      "   macro avg       0.50      0.50      0.13     19738\n",
      "weighted avg       0.82      0.13      0.09     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  742 17020]\n",
      " [   81  1895]]\n",
      "\n",
      "=== Random Forest + SMOTEENN ===\n",
      "Chosen threshold (val F1-max): 0.1433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.01      0.02     17762\n",
      "           1       0.10      0.99      0.18      1976\n",
      "\n",
      "    accuracy                           0.11     19738\n",
      "   macro avg       0.50      0.50      0.10     19738\n",
      "weighted avg       0.83      0.11      0.04     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  180 17582]\n",
      " [   18  1958]]\n",
      "\n",
      "=== Gradient Boosting + SMOTEENN ===\n",
      "Chosen threshold (val F1-max): 0.1123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.00      0.00     17762\n",
      "           1       0.10      1.00      0.18      1976\n",
      "\n",
      "    accuracy                           0.10     19738\n",
      "   macro avg       0.47      0.50      0.09     19738\n",
      "weighted avg       0.76      0.10      0.02     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    5 17757]\n",
      " [    1  1975]]\n",
      "\n",
      "=== XGBoost + SMOTEENN ===\n",
      "Chosen threshold (val F1-max): 0.1222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.04      0.07     17762\n",
      "           1       0.10      0.97      0.18      1976\n",
      "\n",
      "    accuracy                           0.13     19738\n",
      "   macro avg       0.51      0.50      0.13     19738\n",
      "weighted avg       0.83      0.13      0.08     19738\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  637 17125]\n",
      " [   59  1917]]\n",
      "\n",
      "=== Resampling Variants (All Models) — Summary (sorted by PR_AUC) ===\n",
      "             Resampler                Model  Accuracy  Balanced_Acc  \\\n",
      "9          SMOTE-Tomek        Random Forest  0.108724      0.499838   \n",
      "11         SMOTE-Tomek              XGBoost  0.125393      0.500779   \n",
      "13            SMOTEENN        Random Forest  0.108319      0.500512   \n",
      "2    RandomOverSampler    Gradient Boosting  0.103861      0.499609   \n",
      "1    RandomOverSampler        Random Forest  0.103253      0.500621   \n",
      "14            SMOTEENN    Gradient Boosting  0.100314      0.499888   \n",
      "15            SMOTEENN              XGBoost  0.129395      0.503002   \n",
      "12            SMOTEENN  Logistic Regression  0.133600      0.500391   \n",
      "10         SMOTE-Tomek    Gradient Boosting  0.101682      0.500423   \n",
      "8          SMOTE-Tomek  Logistic Regression  0.166025      0.499967   \n",
      "3    RandomOverSampler              XGBoost  0.104519      0.497726   \n",
      "6   RandomUnderSampler    Gradient Boosting  0.133094      0.495612   \n",
      "5   RandomUnderSampler        Random Forest  0.100922      0.500226   \n",
      "7   RandomUnderSampler              XGBoost  0.104925      0.500875   \n",
      "0    RandomOverSampler  Logistic Regression  0.123923      0.499737   \n",
      "4   RandomUnderSampler  Logistic Regression  0.115716      0.501024   \n",
      "\n",
      "    Precision    Recall        F1   ROC_AUC    PR_AUC  Threshold  \n",
      "9    0.100082  0.988866  0.181767  0.517835  0.107183   0.053333  \n",
      "11   0.100256  0.970142  0.181732  0.514242  0.104913   0.063814  \n",
      "13   0.100205  0.990891  0.182004  0.509851  0.104436   0.143333  \n",
      "2    0.100041  0.994433  0.181793  0.507583  0.104144   0.341871  \n",
      "1    0.100224  0.997470  0.182146  0.509415  0.103255   0.073333  \n",
      "14   0.100091  0.999494  0.181961  0.504194  0.102720   0.112311  \n",
      "15   0.100672  0.970142  0.182415  0.507123  0.101923   0.122242  \n",
      "12   0.100185  0.959008  0.181418  0.505419  0.100710   0.647302  \n",
      "10   0.100188  0.998988  0.182112  0.498903  0.100586   0.103571  \n",
      "8    0.100105  0.917510  0.180515  0.503961  0.100116   0.456019  \n",
      "3    0.099699  0.989372  0.181144  0.496596  0.099987   0.197453  \n",
      "6    0.099285  0.948887  0.179761  0.495433  0.099543   0.414145  \n",
      "5    0.100152  0.999494  0.182061  0.497641  0.099398   0.336667  \n",
      "7    0.100270  0.995951  0.182197  0.502372  0.099124   0.223120  \n",
      "0    0.100063  0.969636  0.181405  0.497080  0.098882   0.473039  \n",
      "4    0.100300  0.982794  0.182023  0.497741  0.098534   0.462267  \n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# SCRIPT 2: RESAMPLING VARIANTS (ALL MODELS/RESAMPLERS)\n",
    "# ==================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, balanced_accuracy_score,\n",
    "    classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "\n",
    "# ------------------\n",
    "# Setup & Artifacts\n",
    "# ------------------\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "X_train, X_test, y_train, y_test = joblib.load(\"splits.pkl\")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_proc, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Base models (plain; resampling handles imbalance)\n",
    "# ----------------------\n",
    "models = {\n",
    "    \"Logistic Regression\":\n",
    "        LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Random Forest\":\n",
    "        RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"Gradient Boosting\":\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"XGBoost\":\n",
    "        XGBClassifier(\n",
    "            n_estimators=300, learning_rate=0.1, max_depth=4,\n",
    "            subsample=0.8, colsample_bytree=0.8, eval_metric=\"logloss\",\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "}\n",
    "\n",
    "# ----------------------\n",
    "# Resamplers to test\n",
    "# ----------------------\n",
    "resamplers = {\n",
    "    \"RandomOverSampler\": RandomOverSampler(random_state=RANDOM_STATE),\n",
    "    \"RandomUnderSampler\": RandomUnderSampler(random_state=RANDOM_STATE),\n",
    "    \"SMOTE-Tomek\": SMOTETomek(random_state=RANDOM_STATE),\n",
    "    \"SMOTEENN\": SMOTEENN(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# ----------------------\n",
    "# Helper: train/evaluate\n",
    "# ----------------------\n",
    "def evaluate_resampled(model, model_name, resampler_name, Xtrain, ytrain):\n",
    "    X_res, y_res = resamplers[resampler_name].fit_resample(Xtrain, ytrain)\n",
    "    model.fit(X_res, y_res)\n",
    "\n",
    "    # Tune threshold on validation by F1 (same rule as baseline)\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, val_proba)\n",
    "    f1s = (2 * precisions * recalls) / (precisions + recalls + 1e-9)\n",
    "    best_idx = int(np.argmax(f1s[:-1]))\n",
    "    best_thr = float(thresholds[best_idx])\n",
    "\n",
    "    test_proba = model.predict_proba(X_test_proc)[:, 1]\n",
    "    y_pred = (test_proba >= best_thr).astype(int)\n",
    "\n",
    "    print(f\"\\n=== {model_name} + {resampler_name} ===\")\n",
    "    print(f\"Chosen threshold (val F1-max): {best_thr:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"Resampler\": resampler_name,\n",
    "        \"Model\": model_name,\n",
    "        \"Threshold\": best_thr,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Balanced_Acc\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC_AUC\": roc_auc_score(y_test, test_proba),\n",
    "        \"PR_AUC\": average_precision_score(y_test, test_proba),\n",
    "    }\n",
    "\n",
    "# -----------------\n",
    "# Run: every (resampler x model)\n",
    "# -----------------\n",
    "rows = []\n",
    "for rname in resamplers.keys():\n",
    "    for mname, model in models.items():\n",
    "        rows.append(evaluate_resampled(model, mname, rname, X_tr, y_tr))\n",
    "\n",
    "df_res = pd.DataFrame(rows)\n",
    "print(\"\\n=== Resampling Variants (All Models) — Summary (sorted by PR_AUC) ===\")\n",
    "print(df_res.sort_values([\"PR_AUC\",\"ROC_AUC\"], ascending=False)[\n",
    "    [\"Resampler\",\"Model\",\"Accuracy\",\"Balanced_Acc\",\"Precision\",\"Recall\",\"F1\",\"ROC_AUC\",\"PR_AUC\",\"Threshold\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe11793-79ac-4337-b59e-660c9dcf787e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
